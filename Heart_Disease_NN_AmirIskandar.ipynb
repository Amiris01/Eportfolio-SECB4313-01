{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "model_loc = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "3800f8fc-ddc0-4a20-cdad-e0cb0ce65765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['Untitled0.ipynb', '19 Dec 2022.ipynb', 'Assignment 2 Part B.ipynb', 'Project Progress 3 Code Group 7.ipynb', 'A2_Amzar_Danish_Amir.ipynb', '2 January 2023.ipynb', 'Project Progress 4&5.ipynb', 'Entrez_inclass_exe.ipynb', 'Amir_Ainin_Marnisha_Shahril.ipynb', 'Task2_Amir_Shahril.ipynb', 'Task1_Amir_Shahril.ipynb', 'Lab 1.ipynb', 'Project Progress 2.ipynb', 'PSM1 Data Cleaning.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'heart.csv', '[1_April_2024]_Heart_Disease_NN.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c761400a-2f26-4128-a204-fd40d2f4328b"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "\n",
        "data.head() # display first 5 row data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ea8ee72-42f0-40b7-bd2b-11e8e30ce6f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ea8ee72-42f0-40b7-bd2b-11e8e30ce6f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ea8ee72-42f0-40b7-bd2b-11e8e30ce6f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ea8ee72-42f0-40b7-bd2b-11e8e30ce6f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fc2d5af3-1503-4914-83c6-70f305ccbe8e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc2d5af3-1503-4914-83c6-70f305ccbe8e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fc2d5af3-1503-4914-83c6-70f305ccbe8e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "# The purpose is to explicitly inform the data processing pipeline that these variables should be treated as categorical rather than numerical.\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f70a9d0-99ad-4931-f6d3-88197a291d1c"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-23-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f214fb-16a0-4244-e386-06cb5390fdd9"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values #This line extracts the target variable from the DataFrame data.\n",
        "y = y.reshape(y.shape[0],1) #This line reshapes the y array.\n",
        "x = data.drop(['target'],axis=1) #This line creates the feature matrix x by dropping the 'target' column from the DataFrame data.\n",
        "##\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (303, 21)\n",
            "Shape of y: (303, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a18532b-0217-4d8c-f09f-653e4d720ce3"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "\n",
        "data = pd.DataFrame({'A': [15, 25, 35], 'B': [150, 250, 350], 'C': [1500, 2500, 3500]})\n",
        "print('Original dataset:')\n",
        "print(data)\n",
        "\n",
        "# Normalize data (range 0 - 1)\n",
        "minx = np.min(data)\n",
        "maxx = np.max(data)\n",
        "data_norm = (data - minx) / (maxx - minx)\n",
        "print('\\nNormalized dataset:')\n",
        "print(data_norm)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset:\n",
            "    A    B     C\n",
            "0  15  150  1500\n",
            "1  25  250  2500\n",
            "2  35  350  3500\n",
            "\n",
            "Normalized dataset:\n",
            "     A    B    C\n",
            "0  0.0  0.0  0.0\n",
            "1  0.5  0.5  0.5\n",
            "2  1.0  1.0  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "# After min max normalization the values in the table was ranging from 0 to 1\n",
        "\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "e0c5fab6-a2f1-47b6-9f22-e0cd83ab2977"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bf9089c-5180-48e0-ba12-cd0ec9cb06f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bf9089c-5180-48e0-ba12-cd0ec9cb06f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bf9089c-5180-48e0-ba12-cd0ec9cb06f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bf9089c-5180-48e0-ba12-cd0ec9cb06f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-05b7c50b-e9b0-4335-960e-8b71efeb9c64\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05b7c50b-e9b0-4335-960e-8b71efeb9c64')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-05b7c50b-e9b0-4335-960e-8b71efeb9c64 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c549e8-ebd5-478d-ab75-c5b4b30e15ac"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
        "# re-create train and validation set\n",
        "test_ratio = 0.1 / 0.3\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=test_ratio, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(141, 21)\n",
            "(71, 21)\n",
            "(91, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da439307-4ffe-492f-ade7-459d9d3e61d2"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "# The first layer with 64 neurons is the input layer, receiving the feature inputs and allowing the network to learn hierarchical representations of the data.\n",
        "# The second layer with 32 neurons is the hidden layer, responsible for capturing complex patterns and relationships within the data.\n",
        "# The final layer with 1 neuron is the output layer, producing the network's predictions or classifications.\n",
        "# The softmax activation function in the output layer is typically used for multi-class classification tasks, where it computes the probabilities of each class.\n",
        "# The sigmoid activation function in the final layer is suitable for binary classification tasks, where it squashes the output to a range between 0 and 1.\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "# The first component is mean squared error loss function (loss='mse'). The loss function measures the discrepancy between the model's predictions and the actual target values during training.\n",
        "# The second component is Adam optimizer (optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam')). The optimizer is responsible for updating the weights of the neural network during training to minimize the loss function.\n",
        "# The third component is Metrics (metrics=['acc']). Metrics are used to evaluate the performance of the model during training and validation.\n",
        "# Each of these components affect the model training and performance.\n",
        "# The choice of loss function determines the training objective of the model and guides the optimization process.\n",
        "# The optimizer controls how the model parameters are updated during training, affecting the speed and quality of convergence to an optimal solution.\n",
        "# The selection of performance metrics provides insight into how well the model is performing during training and validation.\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29740616-71dd-4b2a-ea85-81b448690be3"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 1s 31ms/step - loss: 0.2498 - acc: 0.5319 - val_loss: 0.2502 - val_acc: 0.5070\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2473 - acc: 0.5603 - val_loss: 0.2507 - val_acc: 0.5070\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2457 - acc: 0.5603 - val_loss: 0.2500 - val_acc: 0.5070\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2447 - acc: 0.5603 - val_loss: 0.2486 - val_acc: 0.5070\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2413 - acc: 0.5603 - val_loss: 0.2442 - val_acc: 0.5070\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2364 - acc: 0.5603 - val_loss: 0.2376 - val_acc: 0.5070\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.2286 - acc: 0.5603 - val_loss: 0.2270 - val_acc: 0.5070\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.2168 - acc: 0.6596 - val_loss: 0.2147 - val_acc: 0.7324\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.2041 - acc: 0.8298 - val_loss: 0.1999 - val_acc: 0.8169\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1886 - acc: 0.8652 - val_loss: 0.1858 - val_acc: 0.8169\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1729 - acc: 0.8511 - val_loss: 0.1732 - val_acc: 0.8592\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.1594 - acc: 0.8582 - val_loss: 0.1638 - val_acc: 0.8310\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1483 - acc: 0.8511 - val_loss: 0.1557 - val_acc: 0.8310\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1370 - acc: 0.8723 - val_loss: 0.1543 - val_acc: 0.7887\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1278 - acc: 0.8723 - val_loss: 0.1508 - val_acc: 0.7887\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1192 - acc: 0.8865 - val_loss: 0.1477 - val_acc: 0.8169\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1135 - acc: 0.8865 - val_loss: 0.1450 - val_acc: 0.8028\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1076 - acc: 0.9007 - val_loss: 0.1463 - val_acc: 0.7887\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1039 - acc: 0.9007 - val_loss: 0.1474 - val_acc: 0.8028\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.1002 - acc: 0.9007 - val_loss: 0.1435 - val_acc: 0.8169\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0964 - acc: 0.9078 - val_loss: 0.1431 - val_acc: 0.8169\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0917 - acc: 0.9007 - val_loss: 0.1456 - val_acc: 0.8169\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0898 - acc: 0.8865 - val_loss: 0.1464 - val_acc: 0.8028\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0861 - acc: 0.9078 - val_loss: 0.1449 - val_acc: 0.8028\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0835 - acc: 0.9149 - val_loss: 0.1435 - val_acc: 0.8169\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0798 - acc: 0.9149 - val_loss: 0.1434 - val_acc: 0.8169\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0775 - acc: 0.9149 - val_loss: 0.1465 - val_acc: 0.8028\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0753 - acc: 0.9149 - val_loss: 0.1512 - val_acc: 0.8169\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0735 - acc: 0.9220 - val_loss: 0.1446 - val_acc: 0.8169\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0693 - acc: 0.9291 - val_loss: 0.1479 - val_acc: 0.8169\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0671 - acc: 0.9362 - val_loss: 0.1511 - val_acc: 0.8169\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0644 - acc: 0.9362 - val_loss: 0.1509 - val_acc: 0.8169\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0626 - acc: 0.9362 - val_loss: 0.1504 - val_acc: 0.8169\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0610 - acc: 0.9433 - val_loss: 0.1504 - val_acc: 0.8169\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0601 - acc: 0.9433 - val_loss: 0.1494 - val_acc: 0.8169\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0587 - acc: 0.9433 - val_loss: 0.1483 - val_acc: 0.8028\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0578 - acc: 0.9433 - val_loss: 0.1503 - val_acc: 0.8169\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0552 - acc: 0.9433 - val_loss: 0.1484 - val_acc: 0.8028\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0543 - acc: 0.9504 - val_loss: 0.1454 - val_acc: 0.8028\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0525 - acc: 0.9504 - val_loss: 0.1435 - val_acc: 0.8028\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0500 - acc: 0.9504 - val_loss: 0.1389 - val_acc: 0.8028\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0482 - acc: 0.9433 - val_loss: 0.1352 - val_acc: 0.8169\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0445 - acc: 0.9574 - val_loss: 0.1415 - val_acc: 0.8169\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0441 - acc: 0.9574 - val_loss: 0.1442 - val_acc: 0.8169\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0417 - acc: 0.9645 - val_loss: 0.1422 - val_acc: 0.8310\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0409 - acc: 0.9645 - val_loss: 0.1427 - val_acc: 0.8310\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0400 - acc: 0.9645 - val_loss: 0.1458 - val_acc: 0.8310\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0393 - acc: 0.9645 - val_loss: 0.1484 - val_acc: 0.8169\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0390 - acc: 0.9645 - val_loss: 0.1498 - val_acc: 0.8169\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0386 - acc: 0.9645 - val_loss: 0.1493 - val_acc: 0.8169\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0381 - acc: 0.9645 - val_loss: 0.1505 - val_acc: 0.8169\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0377 - acc: 0.9645 - val_loss: 0.1509 - val_acc: 0.8028\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0374 - acc: 0.9645 - val_loss: 0.1518 - val_acc: 0.8028\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0372 - acc: 0.9645 - val_loss: 0.1536 - val_acc: 0.8028\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0368 - acc: 0.9645 - val_loss: 0.1548 - val_acc: 0.8028\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0365 - acc: 0.9645 - val_loss: 0.1558 - val_acc: 0.8169\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0363 - acc: 0.9645 - val_loss: 0.1564 - val_acc: 0.8169\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - acc: 0.9645 - val_loss: 0.1611 - val_acc: 0.8028\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0342 - acc: 0.9645 - val_loss: 0.1638 - val_acc: 0.8028\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0311 - acc: 0.9716 - val_loss: 0.1710 - val_acc: 0.7887\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0309 - acc: 0.9716 - val_loss: 0.1698 - val_acc: 0.7887\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0302 - acc: 0.9716 - val_loss: 0.1712 - val_acc: 0.7746\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0298 - acc: 0.9716 - val_loss: 0.1709 - val_acc: 0.7887\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0295 - acc: 0.9716 - val_loss: 0.1698 - val_acc: 0.7887\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0294 - acc: 0.9716 - val_loss: 0.1695 - val_acc: 0.7887\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0292 - acc: 0.9716 - val_loss: 0.1705 - val_acc: 0.7887\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9716 - val_loss: 0.1716 - val_acc: 0.7887\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0290 - acc: 0.9716 - val_loss: 0.1717 - val_acc: 0.7887\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0290 - acc: 0.9716 - val_loss: 0.1716 - val_acc: 0.7887\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0289 - acc: 0.9716 - val_loss: 0.1726 - val_acc: 0.7887\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0288 - acc: 0.9716 - val_loss: 0.1735 - val_acc: 0.7887\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0288 - acc: 0.9716 - val_loss: 0.1732 - val_acc: 0.7887\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0287 - acc: 0.9716 - val_loss: 0.1734 - val_acc: 0.7887\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - acc: 0.9716 - val_loss: 0.1738 - val_acc: 0.7887\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0286 - acc: 0.9716 - val_loss: 0.1744 - val_acc: 0.7887\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0285 - acc: 0.9716 - val_loss: 0.1746 - val_acc: 0.7887\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0285 - acc: 0.9716 - val_loss: 0.1747 - val_acc: 0.7887\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0285 - acc: 0.9716 - val_loss: 0.1753 - val_acc: 0.7887\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0284 - acc: 0.9716 - val_loss: 0.1758 - val_acc: 0.7887\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0284 - acc: 0.9716 - val_loss: 0.1759 - val_acc: 0.7887\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0284 - acc: 0.9716 - val_loss: 0.1762 - val_acc: 0.7887\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0283 - acc: 0.9716 - val_loss: 0.1767 - val_acc: 0.7887\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0283 - acc: 0.9716 - val_loss: 0.1767 - val_acc: 0.7887\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0283 - acc: 0.9716 - val_loss: 0.1771 - val_acc: 0.7887\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0282 - acc: 0.9716 - val_loss: 0.1772 - val_acc: 0.7887\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0282 - acc: 0.9716 - val_loss: 0.1776 - val_acc: 0.7887\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0282 - acc: 0.9716 - val_loss: 0.1778 - val_acc: 0.7887\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0282 - acc: 0.9716 - val_loss: 0.1782 - val_acc: 0.7887\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0282 - acc: 0.9716 - val_loss: 0.1784 - val_acc: 0.7887\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1785 - val_acc: 0.7887\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1789 - val_acc: 0.7887\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1793 - val_acc: 0.7887\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1791 - val_acc: 0.7887\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1794 - val_acc: 0.7887\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0281 - acc: 0.9716 - val_loss: 0.1797 - val_acc: 0.7887\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1801 - val_acc: 0.7887\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1802 - val_acc: 0.7887\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1801 - val_acc: 0.7887\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1804 - val_acc: 0.7887\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1806 - val_acc: 0.7887\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1809 - val_acc: 0.7887\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1813 - val_acc: 0.7887\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0280 - acc: 0.9716 - val_loss: 0.1814 - val_acc: 0.7887\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1815 - val_acc: 0.7746\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1815 - val_acc: 0.7746\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1819 - val_acc: 0.7746\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1820 - val_acc: 0.7746\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1825 - val_acc: 0.7746\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1826 - val_acc: 0.7746\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1829 - val_acc: 0.7746\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1832 - val_acc: 0.7746\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1833 - val_acc: 0.7746\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1834 - val_acc: 0.7746\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1836 - val_acc: 0.7746\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0279 - acc: 0.9716 - val_loss: 0.1836 - val_acc: 0.7746\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1840 - val_acc: 0.7746\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1839 - val_acc: 0.7746\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1840 - val_acc: 0.7746\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1842 - val_acc: 0.7746\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1844 - val_acc: 0.7746\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1846 - val_acc: 0.7746\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1847 - val_acc: 0.7746\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1849 - val_acc: 0.7746\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1849 - val_acc: 0.7746\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1851 - val_acc: 0.7746\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1854 - val_acc: 0.7746\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1854 - val_acc: 0.7746\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1853 - val_acc: 0.7746\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1855 - val_acc: 0.7746\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1854 - val_acc: 0.7746\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0278 - acc: 0.9716 - val_loss: 0.1857 - val_acc: 0.7746\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1860 - val_acc: 0.7746\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1863 - val_acc: 0.7746\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1862 - val_acc: 0.7746\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1863 - val_acc: 0.7746\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1864 - val_acc: 0.7746\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1866 - val_acc: 0.7746\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1866 - val_acc: 0.7746\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1867 - val_acc: 0.7746\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1868 - val_acc: 0.7746\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1869 - val_acc: 0.7746\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1872 - val_acc: 0.7746\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1872 - val_acc: 0.7746\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1872 - val_acc: 0.7746\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1874 - val_acc: 0.7746\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1874 - val_acc: 0.7746\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1875 - val_acc: 0.7746\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1875 - val_acc: 0.7746\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.9716 - val_loss: 0.1875 - val_acc: 0.7746\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1875 - val_acc: 0.7746\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7746\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7746\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7746\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7746\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1878 - val_acc: 0.7746\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7746\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7887\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1881 - val_acc: 0.7887\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0276 - acc: 0.9716 - val_loss: 0.1882 - val_acc: 0.7887\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1883 - val_acc: 0.7887\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7887\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7887\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1881 - val_acc: 0.7887\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1882 - val_acc: 0.7887\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1884 - val_acc: 0.7887\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1881 - val_acc: 0.7887\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1881 - val_acc: 0.7887\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0275 - acc: 0.9716 - val_loss: 0.1882 - val_acc: 0.7887\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1881 - val_acc: 0.7887\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1879 - val_acc: 0.7887\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0274 - acc: 0.9716 - val_loss: 0.1878 - val_acc: 0.7887\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1877 - val_acc: 0.7887\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1875 - val_acc: 0.7887\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1873 - val_acc: 0.7887\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1873 - val_acc: 0.7887\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1871 - val_acc: 0.7887\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1871 - val_acc: 0.7887\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0273 - acc: 0.9716 - val_loss: 0.1870 - val_acc: 0.7887\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9716 - val_loss: 0.1865 - val_acc: 0.7887\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0272 - acc: 0.9716 - val_loss: 0.1865 - val_acc: 0.7887\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0272 - acc: 0.9716 - val_loss: 0.1864 - val_acc: 0.7887\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0272 - acc: 0.9716 - val_loss: 0.1861 - val_acc: 0.7887\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0272 - acc: 0.9716 - val_loss: 0.1859 - val_acc: 0.7887\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0271 - acc: 0.9716 - val_loss: 0.1855 - val_acc: 0.7887\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0271 - acc: 0.9716 - val_loss: 0.1853 - val_acc: 0.7887\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0271 - acc: 0.9716 - val_loss: 0.1849 - val_acc: 0.7887\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0271 - acc: 0.9716 - val_loss: 0.1845 - val_acc: 0.7887\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0270 - acc: 0.9716 - val_loss: 0.1840 - val_acc: 0.8028\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0270 - acc: 0.9716 - val_loss: 0.1840 - val_acc: 0.8028\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0270 - acc: 0.9716 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 0.9716 - val_loss: 0.1830 - val_acc: 0.8028\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 0.9716 - val_loss: 0.1829 - val_acc: 0.8028\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 0.9716 - val_loss: 0.1824 - val_acc: 0.8028\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0268 - acc: 0.9716 - val_loss: 0.1821 - val_acc: 0.8028\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0268 - acc: 0.9716 - val_loss: 0.1816 - val_acc: 0.8028\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0268 - acc: 0.9716 - val_loss: 0.1812 - val_acc: 0.8028\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0267 - acc: 0.9716 - val_loss: 0.1807 - val_acc: 0.8028\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0267 - acc: 0.9716 - val_loss: 0.1805 - val_acc: 0.8028\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0267 - acc: 0.9716 - val_loss: 0.1802 - val_acc: 0.8028\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0266 - acc: 0.9716 - val_loss: 0.1800 - val_acc: 0.8028\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0266 - acc: 0.9716 - val_loss: 0.1798 - val_acc: 0.8028\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0266 - acc: 0.9716 - val_loss: 0.1795 - val_acc: 0.8028\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0265 - acc: 0.9716 - val_loss: 0.1792 - val_acc: 0.8028\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0266 - acc: 0.9716 - val_loss: 0.1790 - val_acc: 0.8028\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0265 - acc: 0.9716 - val_loss: 0.1787 - val_acc: 0.8028\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0265 - acc: 0.9716 - val_loss: 0.1785 - val_acc: 0.8028\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0264 - acc: 0.9716 - val_loss: 0.1783 - val_acc: 0.8028\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0264 - acc: 0.9716 - val_loss: 0.1779 - val_acc: 0.8028\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0264 - acc: 0.9716 - val_loss: 0.1776 - val_acc: 0.8028\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0264 - acc: 0.9716 - val_loss: 0.1776 - val_acc: 0.8028\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0264 - acc: 0.9716 - val_loss: 0.1774 - val_acc: 0.8028\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.1769 - val_acc: 0.8028\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.1769 - val_acc: 0.8028\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.1768 - val_acc: 0.8028\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0263 - acc: 0.9716 - val_loss: 0.1761 - val_acc: 0.8028\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0262 - acc: 0.9716 - val_loss: 0.1759 - val_acc: 0.8028\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0261 - acc: 0.9716 - val_loss: 0.1751 - val_acc: 0.7887\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0261 - acc: 0.9716 - val_loss: 0.1750 - val_acc: 0.8028\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0261 - acc: 0.9716 - val_loss: 0.1737 - val_acc: 0.7887\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0260 - acc: 0.9716 - val_loss: 0.1719 - val_acc: 0.7887\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0259 - acc: 0.9716 - val_loss: 0.1713 - val_acc: 0.7887\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0259 - acc: 0.9716 - val_loss: 0.1712 - val_acc: 0.7887\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0259 - acc: 0.9716 - val_loss: 0.1696 - val_acc: 0.8028\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0258 - acc: 0.9716 - val_loss: 0.1703 - val_acc: 0.7887\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0258 - acc: 0.9716 - val_loss: 0.1700 - val_acc: 0.7887\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0256 - acc: 0.9716 - val_loss: 0.1674 - val_acc: 0.8028\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0256 - acc: 0.9716 - val_loss: 0.1667 - val_acc: 0.8028\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0254 - acc: 0.9716 - val_loss: 0.1667 - val_acc: 0.8028\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9716 - val_loss: 0.1664 - val_acc: 0.8028\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9716 - val_loss: 0.1661 - val_acc: 0.8169\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0249 - acc: 0.9716 - val_loss: 0.1651 - val_acc: 0.8169\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0249 - acc: 0.9716 - val_loss: 0.1661 - val_acc: 0.8169\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0247 - acc: 0.9716 - val_loss: 0.1674 - val_acc: 0.8028\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0246 - acc: 0.9716 - val_loss: 0.1679 - val_acc: 0.8028\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0246 - acc: 0.9716 - val_loss: 0.1693 - val_acc: 0.8028\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0244 - acc: 0.9716 - val_loss: 0.1687 - val_acc: 0.8028\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0244 - acc: 0.9716 - val_loss: 0.1695 - val_acc: 0.8028\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0241 - acc: 0.9716 - val_loss: 0.1695 - val_acc: 0.8028\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0241 - acc: 0.9716 - val_loss: 0.1709 - val_acc: 0.8028\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0239 - acc: 0.9716 - val_loss: 0.1709 - val_acc: 0.8028\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9716 - val_loss: 0.1716 - val_acc: 0.8028\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0236 - acc: 0.9716 - val_loss: 0.1721 - val_acc: 0.8028\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0234 - acc: 0.9716 - val_loss: 0.1730 - val_acc: 0.8028\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0233 - acc: 0.9716 - val_loss: 0.1735 - val_acc: 0.8028\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9716 - val_loss: 0.1743 - val_acc: 0.8028\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.9716 - val_loss: 0.1751 - val_acc: 0.8028\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0228 - acc: 0.9716 - val_loss: 0.1742 - val_acc: 0.8028\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0228 - acc: 0.9787 - val_loss: 0.1751 - val_acc: 0.8028\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0226 - acc: 0.9787 - val_loss: 0.1775 - val_acc: 0.7887\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0228 - acc: 0.9716 - val_loss: 0.1766 - val_acc: 0.8028\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0223 - acc: 0.9787 - val_loss: 0.1760 - val_acc: 0.8028\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0223 - acc: 0.9787 - val_loss: 0.1767 - val_acc: 0.8028\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0222 - acc: 0.9787 - val_loss: 0.1776 - val_acc: 0.8028\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0221 - acc: 0.9787 - val_loss: 0.1799 - val_acc: 0.7887\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0221 - acc: 0.9787 - val_loss: 0.1790 - val_acc: 0.7887\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0219 - acc: 0.9787 - val_loss: 0.1811 - val_acc: 0.7887\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0218 - acc: 0.9787 - val_loss: 0.1819 - val_acc: 0.7887\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0218 - acc: 0.9787 - val_loss: 0.1822 - val_acc: 0.7887\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0217 - acc: 0.9787 - val_loss: 0.1822 - val_acc: 0.7887\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0216 - acc: 0.9787 - val_loss: 0.1835 - val_acc: 0.7887\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0216 - acc: 0.9787 - val_loss: 0.1841 - val_acc: 0.7887\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0215 - acc: 0.9787 - val_loss: 0.1840 - val_acc: 0.7887\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0215 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.7887\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0215 - acc: 0.9787 - val_loss: 0.1839 - val_acc: 0.7887\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.7887\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0214 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.7887\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0213 - acc: 0.9787 - val_loss: 0.1841 - val_acc: 0.7887\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - acc: 0.9787 - val_loss: 0.1840 - val_acc: 0.7887\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0213 - acc: 0.9787 - val_loss: 0.1839 - val_acc: 0.7887\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0213 - acc: 0.9787 - val_loss: 0.1839 - val_acc: 0.7887\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0212 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.7887\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0212 - acc: 0.9787 - val_loss: 0.1840 - val_acc: 0.7887\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0212 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.7887\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0212 - acc: 0.9787 - val_loss: 0.1835 - val_acc: 0.8028\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1838 - val_acc: 0.7887\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.7887\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0211 - acc: 0.9787 - val_loss: 0.1830 - val_acc: 0.8028\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1831 - val_acc: 0.8028\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0210 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1830 - val_acc: 0.8028\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1832 - val_acc: 0.8028\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0209 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1835 - val_acc: 0.8028\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1834 - val_acc: 0.8028\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1833 - val_acc: 0.8028\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1835 - val_acc: 0.8028\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1838 - val_acc: 0.8028\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1836 - val_acc: 0.8028\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.8028\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1839 - val_acc: 0.8028\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0208 - acc: 0.9787 - val_loss: 0.1838 - val_acc: 0.8028\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1838 - val_acc: 0.8028\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1837 - val_acc: 0.8028\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1839 - val_acc: 0.8028\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1840 - val_acc: 0.8028\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1840 - val_acc: 0.8028\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1841 - val_acc: 0.8028\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1842 - val_acc: 0.8028\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1841 - val_acc: 0.8028\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1842 - val_acc: 0.8028\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1842 - val_acc: 0.8028\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1842 - val_acc: 0.8028\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1842 - val_acc: 0.8028\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1843 - val_acc: 0.8028\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1844 - val_acc: 0.8028\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1845 - val_acc: 0.8028\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1844 - val_acc: 0.8028\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1845 - val_acc: 0.8028\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1846 - val_acc: 0.8028\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1847 - val_acc: 0.8028\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1847 - val_acc: 0.8028\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1848 - val_acc: 0.8028\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1848 - val_acc: 0.8028\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1849 - val_acc: 0.8028\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1850 - val_acc: 0.8028\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1849 - val_acc: 0.8028\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1849 - val_acc: 0.8028\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1849 - val_acc: 0.8028\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1850 - val_acc: 0.8028\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1850 - val_acc: 0.8028\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1851 - val_acc: 0.8028\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1851 - val_acc: 0.8028\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1853 - val_acc: 0.8028\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1853 - val_acc: 0.8028\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1853 - val_acc: 0.8028\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1853 - val_acc: 0.8028\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.9787 - val_loss: 0.1853 - val_acc: 0.8028\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1854 - val_acc: 0.8028\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1855 - val_acc: 0.8028\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1855 - val_acc: 0.8028\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1855 - val_acc: 0.8028\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1857 - val_acc: 0.8028\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1858 - val_acc: 0.8028\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1857 - val_acc: 0.8028\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1858 - val_acc: 0.8028\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1858 - val_acc: 0.8028\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1858 - val_acc: 0.8028\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1859 - val_acc: 0.8028\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1860 - val_acc: 0.8028\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1861 - val_acc: 0.8028\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1860 - val_acc: 0.8028\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1861 - val_acc: 0.8028\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1862 - val_acc: 0.8028\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1862 - val_acc: 0.8028\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1863 - val_acc: 0.8028\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1864 - val_acc: 0.8028\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1864 - val_acc: 0.8028\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1864 - val_acc: 0.8028\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1864 - val_acc: 0.8028\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1865 - val_acc: 0.8028\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1865 - val_acc: 0.8028\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1866 - val_acc: 0.8028\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1869 - val_acc: 0.8028\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1868 - val_acc: 0.8028\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1868 - val_acc: 0.8028\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1868 - val_acc: 0.8028\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1870 - val_acc: 0.8028\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1872 - val_acc: 0.8028\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1871 - val_acc: 0.8028\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1870 - val_acc: 0.8028\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1871 - val_acc: 0.8028\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1872 - val_acc: 0.8028\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1873 - val_acc: 0.8028\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1873 - val_acc: 0.8028\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1874 - val_acc: 0.8028\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1874 - val_acc: 0.8028\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1875 - val_acc: 0.8028\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1873 - val_acc: 0.8028\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1874 - val_acc: 0.8028\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1876 - val_acc: 0.8028\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1875 - val_acc: 0.8028\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1875 - val_acc: 0.8028\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1875 - val_acc: 0.8028\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1876 - val_acc: 0.8028\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1877 - val_acc: 0.7887\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1878 - val_acc: 0.7887\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1880 - val_acc: 0.7887\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1879 - val_acc: 0.7887\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - acc: 0.9787 - val_loss: 0.1878 - val_acc: 0.7887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1ee5917f-2d24-4e0c-fcc1-7f906acccff0"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "# This plot represent the comparison of model's accuracy on training and validation dataset over each epoch.\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "3711a63d-25bc-4351-872c-f3136a870391"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "#plt.savefig('Loss.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaK0lEQVR4nO3deXxU1f3/8dfMJDPZE0JCwh72RTYFRETrQjS4IFqtaPErUJVvrbYq1VZtBZe2UL9o1UrVn61iWxdc6lJRFBBwA1QWQTZB2SEJCWRfJpm5vz9OMiEQEEKSO5N5Px+P+5iZe+/c+UwGkvecc+65DsuyLERERETCiNPuAkRERERamgKQiIiIhB0FIBEREQk7CkAiIiISdhSAREREJOwoAImIiEjYUQASERGRsKMAJCIiImFHAUhERETCjgKQiIS87du343A4mDNnzgk/d8mSJTgcDpYsWXLM/ebMmYPD4WD79u2NqlFEgosCkIiIiIQdBSAREREJOwpAIiIiEnYUgETkpN1///04HA6+/fZbrrvuOhITE0lNTeW+++7Dsix27drFuHHjSEhIID09nUceeeSIY+Tm5nLDDTeQlpZGVFQUgwcP5oUXXjhiv4KCAiZNmkRiYiJJSUlMnDiRgoKCBuvatGkTV111FcnJyURFRTFs2DDeeeedJn3vf/vb3zjllFPweDx06NCBW2655Yh6tmzZwpVXXkl6ejpRUVF06tSJa665hsLCwsA+CxYs4KyzziIpKYm4uDj69OnDvffe26S1ikidCLsLEJHWY/z48fTr14+ZM2cyb948/vCHP5CcnMwzzzzD+eefz5///GdefPFF7rzzToYPH86PfvQjAMrLyzn33HPZunUrt956K926deO1115j0qRJFBQUcNtttwFgWRbjxo3j008/5ec//zn9+vXjzTffZOLEiUfUsn79ekaNGkXHjh25++67iY2N5dVXX+Xyyy/njTfe4Iorrjjp93v//ffzwAMPkJmZyc0338zmzZt56qmn+PLLL/nss8+IjIzE6/WSlZVFZWUlv/zlL0lPT2fPnj28++67FBQUkJiYyPr167n00ksZNGgQDz74IB6Ph61bt/LZZ5+ddI0ichSWiMhJmj59ugVYU6ZMCayrrq62OnXqZDkcDmvmzJmB9QcPHrSio6OtiRMnBtY99thjFmD9+9//Dqzzer3WyJEjrbi4OKuoqMiyLMt66623LMB6+OGH673O2WefbQHW888/H1g/evRoa+DAgVZFRUVgnd/vt84880yrV69egXWLFy+2AGvx4sXHfI/PP/+8BVjbtm2zLMuycnNzLbfbbV144YWWz+cL7Pfkk09agPXcc89ZlmVZq1evtgDrtddeO+qx//KXv1iAtX///mPWICJNR11gItJkbrzxxsB9l8vFsGHDsCyLG264IbA+KSmJPn368P333wfWvffee6Snp3PttdcG1kVGRvKrX/2KkpISli5dGtgvIiKCm2++ud7r/PKXv6xXx4EDB/joo4+4+uqrKS4uJi8vj7y8PPLz88nKymLLli3s2bPnpN7rwoUL8Xq93H777Tiddb9Kb7rpJhISEpg3bx4AiYmJAHzwwQeUlZU1eKykpCQA3n77bfx+/0nVJSLHRwFIRJpMly5d6j1OTEwkKiqKlJSUI9YfPHgw8HjHjh306tWrXpAA6NevX2B77W379u2Ji4urt1+fPn3qPd66dSuWZXHfffeRmppab5k+fTpgxhydjNqaDn9tt9tN9+7dA9u7devG1KlT+fvf/05KSgpZWVnMnj273vif8ePHM2rUKG688UbS0tK45pprePXVVxWGRJqRxgCJSJNxuVzHtQ7MeJ7mUhsc7rzzTrKyshrcp2fPns32+od75JFHmDRpEm+//TYffvghv/rVr5gxYwbLly+nU6dOREdH8/HHH7N48WLmzZvH/PnzmTt3Lueffz4ffvjhUX+GItJ4agESEdt17dqVLVu2HNHisWnTpsD22tt9+/ZRUlJSb7/NmzfXe9y9e3fAdKNlZmY2uMTHx590zQ29ttfrZdu2bYHttQYOHMjvf/97Pv74Yz755BP27NnD008/HdjudDoZPXo0jz76KBs2bOCPf/wjH330EYsXLz6pOkWkYQpAImK7iy++mOzsbObOnRtYV11dzV//+lfi4uI455xzAvtVV1fz1FNPBfbz+Xz89a9/rXe8du3ace655/LMM8+wb9++I15v//79J11zZmYmbrebJ554ol5r1j/+8Q8KCwu55JJLACgqKqK6urrecwcOHIjT6aSyshIwY5YON2TIEIDAPiLStNQFJiK2mzJlCs888wyTJk1i5cqVZGRk8Prrr/PZZ5/x2GOPBVprxo4dy6hRo7j77rvZvn07/fv35z//+U+98TS1Zs+ezVlnncXAgQO56aab6N69Ozk5OSxbtozdu3fz9ddfn1TNqamp3HPPPTzwwAOMGTOGyy67jM2bN/O3v/2N4cOHc9111wHw0Ucfceutt/KTn/yE3r17U11dzb/+9S9cLhdXXnklAA8++CAff/wxl1xyCV27diU3N5e//e1vdOrUibPOOuuk6hSRhikAiYjtoqOjWbJkCXfffTcvvPACRUVF9OnTh+eff55JkyYF9nM6nbzzzjvcfvvt/Pvf/8bhcHDZZZfxyCOPcOqpp9Y7Zv/+/fnqq6944IEHmDNnDvn5+bRr145TTz2VadOmNUnd999/P6mpqTz55JPccccdJCcnM2XKFP70pz8RGRkJwODBg8nKyuK///0ve/bsISYmhsGDB/P+++9zxhlnAHDZZZexfft2nnvuOfLy8khJSeGcc87hgQceCJxFJiJNy2E150hEERERkSCkMUAiIiISdhSAREREJOwoAImIiEjYUQASERGRsKMAJCIiImFHAUhERETCjuYBaoDf72fv3r3Ex8fjcDjsLkdERESOg2VZFBcX06FDhyMurnw4BaAG7N27l86dO9tdhoiIiDTCrl276NSp0zH3UQBqQO20+7t27SIhIcHmakREROR4FBUV0blz5+O62LECUANqu70SEhIUgERERELM8Qxf0SBoERERCTsKQCIiIhJ2FIBEREQk7GgM0Enw+XxUVVXZXUZIcrvdP3iKooiISHNRAGoEy7LIzs6moKDA7lJCltPppFu3brjdbrtLERGRMKQA1Ai14addu3bExMRossQTVDvR5L59++jSpYt+fiIi0uIUgE6Qz+cLhJ+2bdvaXU7ISk1NZe/evVRXVxMZGWl3OSIiEmY0COME1Y75iYmJsbmS0Fbb9eXz+WyuREREwpECUCOp2+bk6OcnIiJ2UgASERGRsKMAJI2SkZHBY489ZncZIiIijRIUAWj27NlkZGQQFRXFiBEj+OKLL46677PPPsvZZ59NmzZtaNOmDZmZmUfsP2nSJBwOR71lzJgxzf02gt65557L7bff3iTH+vLLL5kyZUqTHEtERKSl2R6A5s6dy9SpU5k+fTqrVq1i8ODBZGVlkZub2+D+S5Ys4dprr2Xx4sUsW7aMzp07c+GFF7Jnz556+40ZM4Z9+/YFlpdffrkl3s7x8fvAsuyu4giWZVFdXX1c+6ampmoguIiIhCzbA9Cjjz7KTTfdxOTJk+nfvz9PP/00MTExPPfccw3u/+KLL/KLX/yCIUOG0LdvX/7+97/j9/tZtGhRvf08Hg/p6emBpU2bNi3xdo7N74fCPVjZa+HANvO4hUyaNImlS5fy+OOPB1rF5syZg8Ph4P3332fo0KF4PB4+/fRTvvvuO8aNG0daWhpxcXEMHz6chQsX1jve4V1gDoeDv//971xxxRXExMTQq1cv3nnnnRZ7fyIiIifC1gDk9XpZuXIlmZmZgXVOp5PMzEyWLVt2XMcoKyujqqqK5OTkeuuXLFlCu3bt6NOnDzfffDP5+flHPUZlZSVFRUX1lhNhWRZl3uofXA5mf09ZQTblVX7KSg5SlrvtuJ53tMU6gVakxx9/nJEjR3LTTTcFWsU6d+4MwN13383MmTPZuHEjgwYNoqSkhIsvvphFixaxevVqxowZw9ixY9m5c+cxX+OBBx7g6quvZu3atVx88cVMmDCBAwcOnNDPUkREpCXYOhFiXl4ePp+PtLS0euvT0tLYtGnTcR3jt7/9LR06dKgXosaMGcOPf/xjunXrxnfffce9997LRRddxLJly3C5XEccY8aMGTzwwAONfh/lVT76T/ugEc/MBo7vfTZkw4NZxLiP7yNMTEzE7XYTExNDeno6QOBn/OCDD3LBBRcE9k1OTmbw4MGBxw899BBvvvkm77zzDrfeeutRX2PSpElce+21APzpT3/iiSee4IsvvtD4KxERCTohPRP0zJkzeeWVV1iyZAlRUVGB9ddcc03g/sCBAxk0aBA9evRgyZIljB49+ojj3HPPPUydOjXwuKioKNA6Eg6GDRtW73FJSQn3338/8+bNY9++fVRXV1NeXv6DLUCDBg0K3I+NjSUhIeGoY7lERETsZGsASklJweVykZOTU299Tk5OoJXiaGbNmsXMmTNZuHBhvT+8DenevTspKSls3bq1wQDk8XjweDwn/gZqREe62PBg1nHtuyWnhMpqH12TIokv2mJWpg2ERlwZPTryyNasxoiNja33+M4772TBggXMmjWLnj17Eh0dzVVXXYXX6z3mcQ6/pIXD4cDfguOcREREjpetAcjtdjN06FAWLVrE5ZdfDhAY0HysrpaHH36YP/7xj3zwwQdHtF40ZPfu3eTn59O+ffumKr0eh8Nx3F1RqfEe8koq8VoRxLgjwfKBsxrczX9GldvtPq5LT3z22WdMmjSJK664AjAtQtu3b2/m6kRERFqO7WeBTZ06lWeffZYXXniBjRs3cvPNN1NaWsrkyZMBuP7667nnnnsC+//5z3/mvvvu47nnniMjI4Ps7Gyys7MpKSkBzB/ru+66i+XLl7N9+3YWLVrEuHHj6NmzJ1lZx9dK05wSo00rSUF5Ff6Imm676ooWee2MjAxWrFjB9u3bycvLO2rrTK9evfjPf/7DmjVr+Prrr/npT3+qlhwREWlVbA9A48ePZ9asWUybNo0hQ4awZs0a5s+fHxgYvXPnTvbt2xfY/6mnnsLr9XLVVVfRvn37wDJr1iwAXC4Xa9eu5bLLLqN3797ccMMNDB06lE8++eSkurmaSqwngjhPhDlzzF/TZVRd3iKvfeedd+Jyuejfvz+pqalHHdPz6KOP0qZNG84880zGjh1LVlYWp512WovUKCIi0hIc1omcSx0mioqKSExMpLCwkISEhHrbKioq2LZtG926das38PpElFZW893+Eto6iujoyAdPArTt0RSlh4ym+DmKiIgc6lh/vw9newtQOIr1RNA2zkOF5TYrWqgLTERERAwFIJukJ0RRSU0A8nnN5TFERESkRSgA2cTldBAZGYnPcpgVvip7CxIREQkjCkA2inG7qKqdicCvACQiItJSFIBsFOOOqAtAvmNPMigiIiJNRwHIRoe2AFnVCkAiIiItRQHIRu4IJ9U1AcivACQiItJiFIBs5HA4sFxmMkQFIBERkZajAGQzh8ucCu/QIGgREZEWowBkM2ekCUDOEAhAGRkZPPbYY3aXISIictIUgGwWEWmuT+bEr8kQRUREWogCkM08kRH4rJqPIQRagURERFoDBSCbuSNc+Go+Bl91dbO9zv/7f/+PDh064Pf7660fN24cP/vZz/juu+8YN24caWlpxMXFMXz4cBYuXNhs9YiIiNhJAagpWBZ4Sxu1uKrL8FV7oaqc6rKiE3u+ZR13iT/5yU/Iz89n8eLFgXUHDhxg/vz5TJgwgZKSEi6++GIWLVrE6tWrGTNmDGPHjmXnzp3N8RMTERGxVYTdBbQKVWXwpw6Nfnp0za3nRJ94715wxx7Xrm3atOGiiy7ipZdeYvTo0QC8/vrrpKSkcN555+F0Ohk8eHBg/4ceeog333yTd955h1tvvfVEKxMREQlqagEKIxMmTOCNN96gsrISgBdffJFrrrkGp9NJSUkJd955J/369SMpKYm4uDg2btyoFiAREWmV1ALUFCJjTGtMI5Xk7iDOV0Cpuy2xbTud2OuegLFjx2JZFvPmzWP48OF88skn/OUvfwHgzjvvZMGCBcyaNYuePXsSHR3NVVddhderCRpFRKT1UQBqCg7HcXdFNcgTB1WVWC7PyR3nB0RFRfHjH/+YF198ka1bt9KnTx9OO+00AD777DMmTZrEFVdcAUBJSQnbt29vtlpERETspAAUBBxO8zE4/M13FlitCRMmcOmll7J+/Xquu+66wPpevXrxn//8h7Fjx+JwOLjvvvuOOGNMRESktdAYoCDgcNUEIKv5J0I8//zzSU5OZvPmzfz0pz8NrH/00Udp06YNZ555JmPHjiUrKyvQOiQiItLaqAUoCDhbMAA5nU727j1yvFJGRgYfffRRvXW33HJLvcfqEhMRkdZCLUBBoDYAOS0f1gnM7SMiIiKNowAUBCIiIgFw4cevACQiItLsFICCQG0LkAs/VT4NPBYREWluCkDBwOkCzNn0vmpdEV5ERKS5KQA1UpOO1XE4AxdEtcLkivAa6yQiInZSADpBkZFmvE5ZWVmTHtdfG4B84dECVDvDtMvlsrkSEREJRzoN/gS5XC6SkpLIzc0FICYmBofDcdLH9VY78GFRWVFGpPuEL4saUvx+P/v37ycmJoaICP0TFBGRlqe/Po2Qnp4OEAhBTaG6cD8RlpfyyGqiYwua7LjByul00qVLlyYJjyIiIidKAagRHA4H7du3p127dlRVNc2YnW0v/JluxV/xcceb+NEV/9skxwxmbrcbp1M9sCIiYg8FoJPgcrmabgyLz0tUyS6qC/cRFRXVNMcUERGRBukreJCwPAkAOCuLbK5ERESk9VMAChKO6EQAIqoUgERERJqbAlCQcAUCUInNlYiIiLR+CkBBIiImCQBPdbG9hYiIiIQBBaAg4Y5LBiDapxYgERGR5qYAFCSi4tsAEG2V2lyJiIhI66cAFCSiawJQPKVUVIXH5TBERETsogAUJKJrusDiKaeoIjwuiCoiImIXBaAg4awZBB3vKKeotMLeYkRERFo5BaBgUTMRIkBZ8UEbCxEREWn9FICCRYSbCsxV4MsVgERERJqVAlAQKXPGAlBRfMDmSkRERFo3BaAgUumKA6CqtMDeQkRERFo5BaAgUhkRD0B1mbrAREREmpMCUBCpjjBdYL5yXQ5DRESkOSkABRG/23SB+St0RXgREZHmpAAUTGoCEF5dD0xERKQ5KQAFE48ZA+SoVBeYiIhIc1IACiKuKBOAnFW6IKqIiEhzUgAKIhHRZjboyGp1gYmIiDQnBaAgEhmTaG6ry2yuREREpHVTAAoi7hjTAuT2KwCJiIg0JwWgIBIVa1qAYqwyqn1+m6sRERFpvRSAgkh0fBIAsVRQXFFtbzEiIiKtmAJQEKk9CyzWUU5RRZXN1YiIiLReCkDBxGPGAMVRTlG5WoBERESaiwJQMPGYmaBjqaC43GtzMSIiIq2XAlAwqbkUhsthUVqq64GJiIg0FwWgYOKOxY8DgPLiQpuLERERab0UgIKJw0GlMwaAyjK1AImIiDQXBaAg43WZAOQvVwuQiIhIcwmKADR79mwyMjKIiopixIgRfPHFF0fd99lnn+Xss8+mTZs2tGnThszMzCP2tyyLadOm0b59e6Kjo8nMzGTLli3N/TaahNcVC4CvQleEFxERaS62B6C5c+cydepUpk+fzqpVqxg8eDBZWVnk5uY2uP+SJUu49tprWbx4McuWLaNz585ceOGF7NmzJ7DPww8/zBNPPMHTTz/NihUriI2NJSsri4qKipZ6W41WHWECkFWpACQiItJcHJZlWXYWMGLECIYPH86TTz4JgN/vp3Pnzvzyl7/k7rvv/sHn+3w+2rRpw5NPPsn111+PZVl06NCBX//619x5550AFBYWkpaWxpw5c7jmmmt+8JhFRUUkJiZSWFhIQkLCyb3BE7T78QvodPALXuzwOyZM+U2LvraIiEgoO5G/37a2AHm9XlauXElmZmZgndPpJDMzk2XLlh3XMcrKyqiqqiI5ORmAbdu2kZ2dXe+YiYmJjBgx4qjHrKyspKioqN5iF7/bzAbt8JbYVoOIiEhrZ2sAysvLw+fzkZaWVm99Wloa2dnZx3WM3/72t3To0CEQeGqfdyLHnDFjBomJiYGlc+fOJ/pWmo7bdIE5q0rtq0FERKSVs30M0MmYOXMmr7zyCm+++SZRUVGNPs4999xDYWFhYNm1a1cTVnlirJrLYbiqNAZIRESkuUTY+eIpKSm4XC5ycnLqrc/JySE9Pf2Yz501axYzZ85k4cKFDBo0KLC+9nk5OTm0b9++3jGHDBnS4LE8Hg8ej6eR76JpOT2mCyyyuszmSkRERFovW1uA3G43Q4cOZdGiRYF1fr+fRYsWMXLkyKM+7+GHH+ahhx5i/vz5DBs2rN62bt26kZ6eXu+YRUVFrFix4pjHDBauKHM5jEifusBERESai60tQABTp05l4sSJDBs2jNNPP53HHnuM0tJSJk+eDMD1119Px44dmTFjBgB//vOfmTZtGi+99BIZGRmBcT1xcXHExcXhcDi4/fbb+cMf/kCvXr3o1q0b9913Hx06dODyyy+3620eN1dMIgAen1qAREREmovtAWj8+PHs37+fadOmkZ2dzZAhQ5g/f35gEPPOnTtxOusaqp566im8Xi9XXXVVveNMnz6d+++/H4Df/OY3lJaWMmXKFAoKCjjrrLOYP3/+SY0TaimR0WYMkMevACQiItJcbJ8HKBjZOQ9Q6Zo3iX1rEqv8PRk0/UsiXCE9Tl1ERKTFhMw8QHIkd2wSALFUUOr12VuMiIhIK6UAFGRqu8BiHRWUeattrkZERKR1UgAKNjWnwcdTRmmlApCIiEhzUAAKNh5zGnwsFZRWKACJiIg0BwWgYOM2ASjC4ae8THMBiYiINAcFoGBTE4AAKssKbSxERESk9VIACjZOJ+WOaACqFIBERESahQJQEKp0xgDgVQASERFpFgpAQajSFQuAr1xXhJcQ4vdBdaXdVYiIHBfbL4UhR6pymRYgf6UCkDSzikLYPB9KsiE6GXxeiG4DpXlQkgORURARDf4q2L8ZcjdCwQ7oOgo6DgV/tXmcs8Fs81eZbZExULgL2mRARBS4YyE2BZwR4C01t0mdIakrtOkGbXuAw2H3T0NEmoO31Px+yPkGinMgti3EpUFqP0jpaVtZCkBBqDrCtABZFUU2VyIhq+wAbHgbqitM2DjwPRTthYKdUFkEngSzrWAneEtO/Pib3jVLQ7Ytrbuf883xHS+pC3Q9C9p2h4SOkNDB3CZ1hQj3idcnIienYJcJLVGJ5ktRRSGU5kJJLpTur7nNhZL95otPu35QfhB2fG6+NMWlgq/K/C4q3gc0cNWtkbdC1h9b/K3VUgAKQr7ImjPBGvOHSVo/vw9wmF82B7fDwW1mObDd/KLxlkD2Oqg6zgvqpvSG9kOgLB9cbvPLzRNn1ldXQFW5eb2UXuaXXGwqbHgHKgtNuIptB2mnQNoA0yK0a4W5TegAB3eA5YfKYijLM/cjY0xXWeEuE8Dyt5rbgpeOrC0mBc66A1L7mDCU0kstRSInorqy7gtQhMe0yFp+yNtifoeU5ZsvLaV55otRTDIU7TH/L0/E7i/rPy7aXf9x7e+JxE7mdUtyzO8YGykABSF/zanwjkoFIKnh98F3H8HXr8CmeVBd/sPPSRtggoPPC/EdTDdTfLrp6vKWQGS0+XaXPhicJzgcsMsZR9/Wru+JHctbCts/hT2roHC3+eVbtNfcluXBh7+r2zepK/QbC6ffZLrXRMKBZZkvN3lbTKuKtxiqvSbQFO8z/1cKd9d1L3lLoWif+X9U2ciTaRwu8/vDWwoVBeBJNK06se0OuW1nvhBZfsj71ny56XqmeW5pLrgize+bxE5m3yCjABSErJoA5KxSAAorZQdg/yZY9S/TohPT1rSkFO4xgeXgtiOfE9/BBIHkbuY2oaMJNql9oF3/0GgtccdC7yyzHKraC18+C98thuJsyN9ixhstexJWPAO9LoRBV0PfS8GlX2USZCzLdDf7faYLyVdlupHyt5qWVV+Vuc3daMJCdaVZHA4TIPK3mhbe6oqa/b2Nr8UdZ748+Gte0+83X4ji0kxrb/vB0O4U0zJTUQhRCeZLTlRik/04gpF+awSjmuuBRSoAtV6lebB1EWz72Pxhz99qmqKPJSoRBl8LA682A4g98SbstFYRbhh5i1nAfBPdugi+eg6+Xwyb55kltS9c+hfzzVOkqVmW6QYuP1jXdVO01wQJT7z5v1w7FqZ2jExZvlmqK5quDofLfMlxx5iWlogoc/z49qa7ObGTCTRl+SbwJHQwS1w703pzoq28YUABKAg5o5MAiKxWAAp5tWdTbXrPjHlxuWHvatizkgYHBSZ0hC4joc9Fdd8eEzubLq8e57f6b2TH5I6F/peZZd9a2PAWfPW8aTV7/iLofp4ZY3Da9aYFTI6P3w+fPgrf/Me0VAy4wvy7Te1rAvbKF0wXSJsM84fVGWH+qOZ8Y37mfS+B6CQTCrYsMK0YXc6A9oNa8D34TOsgDvN/qHbgfGmeOXux/ID5f1R+0IxVcThMKPDEme6jfV+b4FJdaQKEt8SMP/OWmJZZX1NN7+AwX17c8abV0hlZ03rbreaMyyjzXnyVkNwDkrubkOWKhLh0nRDQxBSAgpAz2vyR8/gUgEKKZcHur+Db980ZFAe3mccNBR2A9IHQMxPSB0HbnqZJ2h3boiWHrPaDzDLyVlh4P6x6wbQKfb8Ylv8NMh8wrWVxqXZXGvz++ytY/a+6xzs+bXi/HZ8duW7da/CO07RCFO2pv23IBPPHffunJjjFtDVhNbWPGatSVWa6XhI7wd415nFyd/MlwfLVnW1UO31CbQtMeYHZ1+U2wcDvN62ota0tzkgzWL+iwAyub6zyg/UfOyPMeJbYFPN+I6PrglLtWJi4dmZsTGyKeb+xqeBwmm6lCHdNy42n8TVJk3JYlnWU387hq6ioiMTERAoLC0lISGjx19+59AW6LP4VKx0DGDq9gV86Ely2LjJ/CHYub3icTlSS+Tbd7UemD75tL+hxnmmelqaxby3s+crMabTlg7r1g38K5//O/JGV+izLnP3zz3Hmj/R595owseldE1z2f2v+vWacZeZ2OrjdBI/S/Sbgpw+ELR+awa8AOKDz6abFYuvCln8/EVHm9vBup6QuJowU7jHdR52Gm30ri80Sk2zOgkzqYgJVbKoJKmX55r3EJJvg444NjTF1Ye5E/n6rBSgIRcYkARBj6WrwQcmyTNP6V/8wY3gO/WYcGWu6BNIHmAHKXUaYX6zSvGpbhIZOhhVPw/KnTJfI1y/B2rkwdCKMnma6eMKd3w+fP2EGkhfvNetO/R/40V3m/rm/Pf5jZf3RDFA/sK1mUG3NmT67vjCD1Uv2wylXAJbpImvbE3I3mPAfk2LGcHnLoOtIEzoKdpoziqCuJaUk1zyOblOzJJl9/VVmILHlN8dtk2GCXMFO06UVEWXGhXniGihcRC1ADbK7BSh/4ye0nXspO612dL7/Wxz61mEvyzKnoH/x/+rm0zh8jqahk6DHaOg5Wt1YwWLXl7DoAdj+iXkcmwpZf4KBPwnfb/KWBW/dDF+/XLcuvj1MWQrxafbVJdJE1AIU4jxxSQDEUYbX58cT4bK3oHBTUWQCTul+WP+mWQ5uP3K/tIFw+o3Q6XRI69/iZcoP6DwcJr0L2z6BeVNNV81/boKPZ0Hfi+H0KeHXDbllgQk/Dhdc/DAMuLJuQK5ImNG/+iAUHW+a6eMpp6SiGk+cAlCzq6qAda/C8qchd/2R2yNjTCtPn4vMWSbx7c14Agl+3c6Gn38Gy/5qwk/eZvh0M3z2uDnjru+lptuyTVe7K20+xdnw4e/h+5rLlJx+Ewy/0d6aRGymABSEXDVngUU6fJSWFtMmTmcNNDm/D755A9a8ZAY5bvvEzOFRy+EyAyJ7XQCn/NhM0qeurdAV4Yazf23GCH2/GL74O+z83Izf2vEZfHCPORuv31joc7E5nb41dZN9/lczUL/WoPH21SISJBSAgpE7Dh9OXPipKDkIaSl2V9Q6VJaYs1N2f2m6AvI219+e0BFG/BxOvc4MtrT84FTrW6sSk2y6fQZcaQbLbpoHG981YSh7rVkW/xESu0DvC814oWNd9iMUWBasf6vucdte0OFU28oRCRYKQMHI4aCUGBIoobKkwO5qQt/ulbDhTVj9opkQrVZUIoy42QSd1D7Qf5xp9anlUPhp1ZK6wBk3m6U0Dza/b04B/34JFO6EL/9ulv6Xm0koIzxm3qbYIP9CUl1pTgWvnTQze23dhSnP/KV5P62pdUukkRSAglSZM4YEfwlVZQd/eGepz1tmJh5b/W9zBtC2pXXbkrqaa0ilDzB/CGpm3ZYwF5sCp/2PWbxlJgRtfMdcfHbDW2YBM8nembdCx2Hm307nM4JrALFlwXNjzEUzr3/btPQsfdhs6zcWLvyDvfWJBJEg+p8rhyp3xoE/l+rSRl7JNxxVlsAns8x4B3/1IRscMODH0O8yXThTfpg7xpwl1vdiOOMXZpbpA9vMWYHZa+HTv9Tt23kETHgteC5RkrsR9q4y9//9Y+g9xrRqudww6g57axMJMvpLEKQqXbFQDdXlCkA/aOO7sPJ5M7an4pCfV/ogM8Fb93N0bShpnPaD4JJH6h5veBtW/cv8O8vdALtWwKze5oyqC/9gf9fSpnl19ysKYO0r5v642dBpqC0liQQrBaAgVRkRD5WY697IkSwLivfBogfrT+qW3B0ueNBMSqjT1KWp9R9nFjAXtX1tkpkjatmT5ppXQ34KI/63ZWuqLIbFM6DDENNtB3DBQ+Zst+2fmgA36OqWrUkkBCgABamqiHgArMoimysJMt5Sc/HL9W+aLgkw09+PvMV0b3UarjO3pGV0OBV+tQZW/dNcUHTfGrOk9oHu57ZMDd4yeOma+hcwdUaYC8GO+pX5/6LpG0QapAAUpHyR5vo1jnAPQH4f7FwGyT3Maevz7z1kokIHpA2AS2aF/qnKEpocDnOdsdQ+8O4dplvsg9/D/y5t/iBeVQGv/o8JPw5n3TW0LvozxKWa+wo/IkelABSkfB5zDRNnZbHNldjI74c3f25maD5UbCpc9te6U5NF7NblDJj4LjxxKuSsM/NM9RnTfK+X/x3Mvc4ErsgYuO4NyFlvLkZa20UnIsekABSkLE/NbNDeMB4EvWRG/fATlQgDroJz76676rRIsIhta06jX/YkfPls8wWgikJ4aTzkbzFfBq563lz1vOuZzfN6Iq2UAlCQ8seYydY8Va14HiBftekmOPTMmc3zzRlduRvMTL0AVzxjrtUUGQtOpz21ihyP4TfAstlmxvGvX4FTrmjaVsody8zV3A9uMzOX3/QRxKc33fFFwoj+mgQpZ0xbAGKqCuwtpKnlbjTdWqv+BX/qALNHwLcfmm17VsLcCfDt/LrwM/inMPga8MQr/EjwS+4OA68y99/8X5jVy4SWk7Xxv/Dq9fDCpSb8xLeHa19W+BE5CWoBClLOeNMCFOtrZV1gH/3BTMxWe+p63mZ4bSLc8CG8cZOZwLDT6WZgadkBXbFaQs/lT0HbnqYLt6IQXrnWtASlDTCnyUdGn9jxDm6H1yaDv8o87j8OLnsSohKavHSRcKIAFKTc8eYsjgR/oZnzxu4J1ppKwY76j1P7wv5N8PRZ5nFCR5jwqrkYqUgockWacWrDb4RH+0P5QfjqObNtx+dw1T9++BgHt0NcOmz5AN67y4QfTyKMfcxcwkWtoSInTQEoSEUlpgHgwQtVZa3ndFa/v+7+ufeYb8R/z4SSHMABVzyt8COtQ2yKmYvn4/8Dlwd8lWaiwsoS8MQd/XnffgAvXwNRSfUv3jvxHTPZoYg0CQWgIBUbl0ClFYnHUWWuVN1aAlDxXnN7/dvQ7RzTsvXLlbD2VTOeoduP7K1PpCmd9zvofZG5+O7sEWb8zvdLoN+lDe/vq4YPf2/m9KkNP/3GwqDxCj8iTUztqEEqLjqSfMxs0P7SfJuraSJV5aY7AKD94LpuPU+8OXum7yX21SbSHBwOcw2uCA/0zjLrvp3f8L6VxfDGDZD3rXk84CoY+wSM/7cJQSLSpNQCFKTiPBF8Z8XTwXGAisIcYjrZXVETKN5nbiOiTfO+SDjpPQZWPG1Oj49OgoyzzSUzak+Tf+8u2PCWuZTFFc/UnU0mIs1CAShIRUW6OIg5y6OyaD+t4rKeRTUBKKF96xnULXK8up8LA66Eb96Az/9qlqhEGHg19Lmo5sxIB/zPm+oKFmkBCkBBrNiVCBZUFe+3u5SmUdsCFN/B3jpE7OBwwBX/D9r1NxdN3fUllGSbWaO/qjkzbOhEhR+RFqIAFMRKXUlQDb6SPLtLaRpFNQOgE9rbW4eIXVwR8KM7zX2/D9a/CW/caAY9t+kGFzxob30iYUQBKIiVRyZCNVilrSQABVqAFIBEcLrMOJ+yA7B2rpnjJyrR7qpEwoYCUBCriEyGcnCWtZKzwGovb5GgLjCRgBFTzCIiLUqnwQexqihzPTBXeStoAfL7YWfNNZHaD7a3FhERCXsKQEGsKtpcDsNT0QoCUPZaKMsHdxx0Gm53NSIiEuYUgIKYP9YEoGhvnrkeWCj7frG5zTjLXCtJRETERgpAwSy2HQCR/kozS2wo+36pue1+nr11iIiIoAAU1Dyx8RRb0eZBSa69xZysnPXmVt1fIiISBBSAglh8VCT7rZrTYkty7C3mZJQfhNKaAJfa295aREREUAAKaglREewnyTwoDeEWoP01F3dM6GgufCoiImIzBaAglhB9aAtQCAegvM3mNkWtPyIiEhwUgIJYYnQk+60k8yCUu8D21wSg1D721iEiIlJDASiIJUa3kjFAeTVdYGoBEhGRIKEAFMQSoyMDY4Cs4hDtAlvzUt0p8Kl97a1FRESkhq4FFsQO7QKzcjfg8FWbq0mHim0fw1u/ACzoPQa6jLS7IhEREUAtQEEt0uXkm4hTyLficRbthq9fsruk41deAP+ZAlgw+Kdwzcvg1D83EREJDvqLFOTc0fH8rfoy8+DTx2yt5YQsvB+K90FyD7hklsKPiIgEFf1VCnIJ0ZG84jsfCwcc+A6KQ2AwdM4GWPm8uX/ZE+COtbceERGRwygABbnE6EhKiaY4oadZsecrews6Hl/9w9z2vdRc/FRERCTI2B6AZs+eTUZGBlFRUYwYMYIvvvjiqPuuX7+eK6+8koyMDBwOB4899tgR+9x///04HI56S9++oXv2UWK0uXJ6bsIAs2J3kAegiiL4eq65f/pN9tYiIiJyFLYGoLlz5zJ16lSmT5/OqlWrGDx4MFlZWeTmNnzKd1lZGd27d2fmzJmkp6cf9binnHIK+/btCyyffvppc72FZlcbgHbF9DcrGtMCtPY1eGk8VBRCaT588Dv45BEo2NmElQLeMnjjRvAWQ9te0O2cpj2+iIhIE7H1nOpHH32Um266icmTJwPw9NNPM2/ePJ577jnuvvvuI/YfPnw4w4ebq4k3tL1WRETEMQNSKKkNQFvdfTkPYM8q8PvA6Tr+g/znRnO7/CnweWHZk+bxJ3+B3llwyhXQ71LYucJMWnjqdeBwnFihe1aakFW6HyKi4PK/nfgxREREWohtLUBer5eVK1eSmZlZV4zTSWZmJsuWLTupY2/ZsoUOHTrQvXt3JkyYwM6dx27pqKyspKioqN4SLJJiTAD6zuoMngTwlkD2uuM/gK+q7n5ZPuw45GfrLYZvXoe518Gm9+Dla+CdW2HrwuM//qZ58NxF8Oz5JvwkdYFrXoLOpx//MURERFqYbQEoLy8Pn89HWlpavfVpaWlkZ2c3+rgjRoxgzpw5zJ8/n6eeeopt27Zx9tlnU1xcfNTnzJgxg8TExMDSuXPnRr9+U6ttASqo8EOXM8zKHZ8f/wEOfF93v7rCtNQA/GIFXPkP6DQcsOCVa6H8gNm26p/Hd+yKQnj7FthZU09MCvzvx9Bz9PHXJyIiYgPbB0E3tYsuuoif/OQnDBo0iKysLN577z0KCgp49dVXj/qce+65h8LCwsCya9euFqz42BJqAlBheRV0PdOs3PHZ8R+g9kKkAJvng6/SBJXUPjDwKpg0D9IH1n/O5vehNO+Hj/35X6H8oLnvSYSxj0F0m+OvTURExCa2BaCUlBRcLhc5OfXntcnJyWnS8TtJSUn07t2brVu3HnUfj8dDQkJCvSVYJNYLQDWnlO/4HPx+MxYob8uxD5B3SAAqrRlc3uWMuvE5ER647Mm6feLSwV8F384/9nEtC1a/aO7/ZA7cvQP6jT2+NyUiImIz2wKQ2+1m6NChLFq0KLDO7/ezaNEiRo5sumtGlZSU8N1339G+ffsmO2ZLqheAOgyByFjTVZXzDbx6PTw5DL794OgHOLQFqFZtV1qtDkNgwutw1fMw5Kdm3fYfaGXKWQ/FeyEiGnpfpAHPIiISUmztAps6dSrPPvssL7zwAhs3buTmm2+mtLQ0cFbY9ddfzz333BPY3+v1smbNGtasWYPX62XPnj2sWbOmXuvOnXfeydKlS9m+fTuff/45V1xxBS6Xi2uvvbbF319TqBeAXJHQ7Wyz4bWJsOldc3/jf81tSS68/rO6lhk4SgBqIGD2ugAG/Lhu4sLtPzB1wJYPzW33cyAy6jjfjYiISHCw9TT48ePHs3//fqZNm0Z2djZDhgxh/vz5gYHRO3fuxHnINaT27t3LqaeeGng8a9YsZs2axTnnnMOSJUsA2L17N9deey35+fmkpqZy1llnsXz5clJTU1v0vTWV2gBUUllNtc9PRM9M0z116ODm/O+gshheuAz2b4Rv3oAe50FUIuRuqH/AiGhIH3T0F+w8ApwRULgTDu6ANl0b3m/LAnPb64KTeHciIiL2sDUAAdx6663ceuutDW6rDTW1MjIysCzrmMd75ZVXmqq0oFAbgACKKqpJ7nH+kTtlr4NV/zLhp9bSP8MpPwZ/NSR0AneMmeOn0zCIcB/9BT1x0OE02P0FfPcRDJt85D7eMrMdoIfO+BIRkdDT6s4Ca20iXE7iPCanFpZXQdsekDYAcMB1/zGTDnqLYfnfzBNqByKv+hes/pe533UkJNac2n/4+J+G9L3E3K7+d906y4Iv/2FC0e4v64JVm4yTfo8iIiItzfYWIPlhidGRlFRWmwAEcN0bZrxP+0GQdoqZ26ew5tT9zAegutKM0Vn3mlnX9UwTVvxVMHTSD7/gkAnw0R/MZTey15nT5Hd8BvOmmu0jb607rgY/i4hICFILUAioNxcQQHy6CT9QM5Fhjba9TAvR+fcBhwSTrqOg94Uw8b+Q2OmHXzAuFfpcZO5veNvcfvdR3fbaS2nUzkskIiISYtQCFAISo83HVFDmPXLjOb+Fg9vNwOjhNdf8aj8IfjoXvltsAlFqnxN/0a5nwsZ3ILdmXNHWRUfuU3vGmIiISIhpVAvQCy+8wLx58wKPf/Ob35CUlMSZZ57Jjh07mqw4MWoHQheVVx25MSbZhJ1798GI/61b3zsLLpoJp9/UuBetDU37N0PJfti3pv72s38NKb0ad2wRERGbNSoA/elPfyI6OhqAZcuWMXv2bB5++GFSUlK44447mrRAgaRoc9ZWYUMBqJY7pmnH46T2NbcHvoedNRdQTe0HNy02y+hpTfdaIiIiLaxRXWC7du2iZ8+eALz11ltceeWVTJkyhVGjRnHuuec2ZX0CJMYcNgaoJcS3N1efryyC7xebdW17QMfTWq4GERGRZtKoFqC4uDjy8/MB+PDDD7ngAjMZXlRUFOXl5U1XnQCHzQbdUhwOSOlt7m9ZaG6TurTc64uIiDSjRrUAXXDBBdx4442ceuqpfPvtt1x88cUArF+/noyMjKasT2jgLLCWktrXnApfuNM8Pp4zyEREREJAo1qAZs+ezciRI9m/fz9vvPEGbdu2BWDlypUhe82tYFbbAlRQ1sIBqF2/wwrp3LKvLyIi0kwa1QKUlJTEk08+ecT6Bx544KQLkiPZ0gUG5irx9QpRC5CIiLQOjWoBmj9/Pp9+Wne18NmzZzNkyBB++tOfcvDgwSYrToxjngbfnNoPrv9YY4BERKSVaFQAuuuuuygqKgJg3bp1/PrXv+biiy9m27ZtTJ06tUkLFEiOMafBH2hoIsTm5IkHl6fucUzbln19ERGRZtKoLrBt27bRv39/AN544w0uvfRS/vSnP7Fq1arAgGhpOslxJgBVVPkp81YT427BCbxjU6Fot7mv636JiEgr0agWILfbTVlZGQALFy7kwgsvBCA5OTnQMiRNJ9btwhNhPqr8khZuBepbE2gPbQkSEREJcY1qSjjrrLOYOnUqo0aN4osvvmDu3LkAfPvtt3TqpIGyTc3hcJAS52FPQTn5pV46J8e03IuPng4RUTDgypZ7TRERkWbWqBagJ598koiICF5//XWeeuopOnbsCMD777/PmDFjmrRAMdrWdIPll1S27At74uDCh448I0xERCSENaoFqEuXLrz77rtHrP/LX/5y0gVJw5JjawNQC3eBiYiItEKNHk3r8/l466232LhxIwCnnHIKl112GS6Xq8mKkzptY80YnPxSBSAREZGT1agAtHXrVi6++GL27NlDnz59AJgxYwadO3dm3rx59OjRo0mLFEixqwtMRESkFWrUGKBf/epX9OjRg127drFq1SpWrVrFzp076datG7/61a+aukbhkC4wtQCJiIictEa1AC1dupTly5eTnJwcWNe2bVtmzpzJqFGjmqw4qdM2Tl1gIiIiTaVRLUAej4fi4uIj1peUlOB2u0+6KDmSbWeBiYiItEKNCkCXXnopU6ZMYcWKFViWhWVZLF++nJ///OdcdtllTV2jAG11FpiIiEiTaVQAeuKJJ+jRowcjR44kKiqKqKgozjzzTHr27Mljjz3WxCUK1HWBHSj1YlmWzdWIiIiEtkaNAUpKSuLtt99m69atgdPg+/XrR8+ePZu0OKlT2wLk9fkprqwmISrS5opERERC13EHoB+6yvvixYsD9x999NHGVyQNiop0Eet2Uer1kV/iVQASERE5CccdgFavXn1c+zl0xfBm0zbOQ+mBMg6UVtItJdbuckRERELWcQegQ1t4xB5t49zsPFBGngZCi4iInJRGDYIWe+hMMBERkaahABRCaq8HdqBUcwGJiIicDAWgEFI7GaK6wERERE6OAlAI0fXAREREmoYCUAhJiVMXmIiISFNQAAohddcDUwuQiIjIyVAACiG1XWAaAyQiInJyFIBCSG0X2MEyL36/rgcmIiLSWApAIaRNjGkB8vktCsqrbK5GREQkdCkAhRB3hDMwGeK+wnKbqxEREQldCkAhpnNyDAC7DpTZXImIiEjoUgAKMXUBSC1AIiIijaUAFGI6t4kGYNdBtQCJiIg0lgJQiOlS0wK0U11gIiIijaYAFGI0BkhEROTkKQCFmNoWoF0HyzUXkIiISCMpAIWY9olRuJwOvNV+9pfommAiIiKNoQAUYiJcTjokRQEaByQiItJYCkAhqHMbjQMSERE5GQpAIaguAGkuIBERkcZQAApBXdrqVHgREZGToQAUgjppMkQREZGTogAUgrpoLiAREZGTogAUgmonQ8wuqqCy2mdzNSIiIqFHASgEtY11Ex3pwrJgb0GF3eWIiIiEHAWgEORwOALdYNvzS22uRkREJPQoAIWonmlxAGzcV2RzJSIiIqFHAShEDeqYCMA3ewptrkRERCT0KACFqIE1AWidApCIiMgJUwAKUafUBKBdB8o5WOq1uRoREZHQogAUohKjI8momRH6m71qBRIRETkRCkAhbEBNK9Da3QpAIiIiJ0IBKIQN6qSB0CIiIo1hewCaPXs2GRkZREVFMWLECL744ouj7rt+/XquvPJKMjIycDgcPPbYYyd9zFA2QAOhRUREGsXWADR37lymTp3K9OnTWbVqFYMHDyYrK4vc3NwG9y8rK6N79+7MnDmT9PT0JjlmKKsNQLsPaiC0iIjIibA1AD366KPcdNNNTJ48mf79+/P0008TExPDc8891+D+w4cP5//+7/+45ppr8Hg8TXLMUJYQFUm3lFhArUAiIiInwrYA5PV6WblyJZmZmXXFOJ1kZmaybNmyFj1mZWUlRUVF9ZZQoW4wERGRE2dbAMrLy8Pn85GWllZvfVpaGtnZ2S16zBkzZpCYmBhYOnfu3KjXt0PtjNDrdCaYiIjIcbN9EHQwuOeeeygsLAwsu3btsruk46YWIBERkRMXYdcLp6Sk4HK5yMnJqbc+JyfnqAOcm+uYHo/nqGOKgt0pHRMA2FNQzoFSL8mxbpsrEhERCX62tQC53W6GDh3KokWLAuv8fj+LFi1i5MiRQXPMYJcQFUl3DYQWERE5Iba1AAFMnTqViRMnMmzYME4//XQee+wxSktLmTx5MgDXX389HTt2ZMaMGYAZ5Lxhw4bA/T179rBmzRri4uLo2bPncR2zNRrQMZHv80pZt7uAc3qn2l2OiIhI0LM1AI0fP579+/czbdo0srOzGTJkCPPnzw8MYt65cydOZ10j1d69ezn11FMDj2fNmsWsWbM455xzWLJkyXEdszUa0DGBd77ey8Z9xXaXIiIiEhIclmVZdhcRbIqKikhMTKSwsJCEhAS7y/lBizflMnnOl/RJi+eDO35kdzkiIiK2OJG/3zoLrBXo2S4OgG15pVT7/DZXIyIiEvwUgFqBjknRREU68fr87DpYbnc5IiIiQU8BqBVwOh30SDWtQFtyNA5IRETkhygAtRK13WBb95fYXImIiEjwUwBqJXrWtABtzVEAEhER+SEKQK3E4M5JACzenEtFlc/eYkRERIKcAlArMapnCu0TozhYVsUH6xt3MVkREZFwoQDUSricDn4yzFzF/vWVu22uRkREJLgpALUiFw80F3xdteMgfr/mtxQRETkaBaBWpGdqHNGRLkq9Pr7PK7W7HBERkaClANSKRLicnNLBTP29bk+BvcWIiIgEMQWgVmZAx0QA1u0usrkSERGR4KUA1MoM6lQTgNQCJCIiclQKQK1M7XxAX+8upMxbbW8xIiIiQUoBqJXpnhJLpzbReKv9fLY13+5yREREgpICUCvjcDjI7JcGwEebcmyuRkREJDgpALVC5/dtB8CijblYluYDEhEROZwCUCs0onsybpeT3OJKdh8st7scERGRoKMA1Ap5Ilz0bR8PwNe7C+wtRkREJAgpALVSAwPzARXaXImIiEjwUQBqpQZ3SgJgrQKQiIjIERSAWqmBNRMifrOnUBdGFREROYwCUCvVq10cMW4XxZXVfLNXrUAiIiKHUgBqpSJcTs7tkwrA+99k21yNiIhIcFEAasUuHtgegPfX7dN8QCIiIodQAGrFzuvTDk+Ek+35ZWzcV2x3OSIiIkFDAagVi/VEBLrB3lu3z+ZqREREgocCUCtX2w32nrrBREREAhSAWrnz+7bD7XLyfV4pm7LVDSYiIgIKQK1efFQk5/U13WAvrthhczUiIiLBQQEoDEw8MwOAN1buobCsyt5iREREgoACUBgY2b0tfdPjKa/y8d43GgwtIiKiABQGHA4H59ScDbZhb5HN1YiIiNhPAShM9EtPAGCzBkKLiIgoAIWLPunxAGzMLtLp8CIiEvYUgMJEj9Q4IpwOiiuq2VtYYXc5IiIitlIAChPuCCc928UBsDlb44BERCS8KQCFkdpusLW7C22uRERExF4KQGHkzB5tAZj/TbbNlYiIiNhLASiMjDmlPZEuB5uyi3U2mIiIhDUFoDCSGBPJOb3NfED//XqvzdWIiIjYRwEozNReHX7x5lybKxEREbGPAlCYObuXaQFav7eI/cWVNlcjIiJiDwWgMJMa7+GUDmZW6E+37re5GhEREXsoAIWh2nFAH21SABIRkfCkABSGsk5JB+CD9dkcKPXaXI2IiEjLUwAKQ4M6JTKwYyLeaj+vfbXL7nJERERanAJQGHI4HFx3RhcA/rlsB1U+v80ViYiItCwFoDA1bkhHUuLc7CkoZ97afXaXIyIi0qIUgMJUVKSLyaO6AfD4oi0UV1TZXJGIiEjLUQAKY9ed0ZW0BA/b8kq5Y+7XWJZld0kiIiItQgEojCVGR/L//mcYbpeThRtzWPqtTosXEZHwoAAU5gZ3TuL6kV0B+L8PNmtAtIiIhAUFIOEX5/UkzhPB+r1F/PaNteoKExGRVk8BSEiOdfP4NUNwOR38Z9UeVu44aHdJIiIizUoBSAAY3S+NS2quFL9ks8YCiYhI66YAJAG11wjTYGgREWntFIAk4OzeKQCs21PI/uJKm6sRERFpPgpAEtAuPoqBHRMBuOc/a6nWGWEiItJKKQBJPfdf1h93hJOFG3N5+UtdKFVERFonBSCpZ2jXZH47pi8Acz7bht+vU+JFRKT1UQCSI4wf3pk4TwTf7S/l0615dpcjIiLS5IIiAM2ePZuMjAyioqIYMWIEX3zxxTH3f+211+jbty9RUVEMHDiQ9957r972SZMm4XA46i1jxoxpzrfQqsR5IvjxaR0BeOfrvTZXIyIi0vRsD0Bz585l6tSpTJ8+nVWrVjF48GCysrLIzc1tcP/PP/+ca6+9lhtuuIHVq1dz+eWXc/nll/PNN9/U22/MmDHs27cvsLz88sst8XZajTED0gFYsjlX3WAiItLq2B6AHn30UW666SYmT55M//79efrpp4mJieG5555rcP/HH3+cMWPGcNddd9GvXz8eeughTjvtNJ588sl6+3k8HtLT0wNLmzZtWuLttBrDM5KJ90SQV+Jl7Z5Cu8sRERFpUrYGIK/Xy8qVK8nMzAysczqdZGZmsmzZsgafs2zZsnr7A2RlZR2x/5IlS2jXrh19+vTh5ptvJj8//6h1VFZWUlRUVG8Jd5EuJz+qmRhx4YYcm6sRERFpWrYGoLy8PHw+H2lpafXWp6WlkZ2d3eBzsrOzf3D/MWPG8M9//pNFixbx5z//maVLl3LRRRfh8/kaPOaMGTNITEwMLJ07dz7Jd9Y6ZNV0g72+crfmBBIRkVYlwu4CmsM111wTuD9w4EAGDRpEjx49WLJkCaNHjz5i/3vuuYepU6cGHhcVFSkEAVmnpNE21k12UQULN+YGxgWJiIiEOltbgFJSUnC5XOTk1O9iycnJIT294T+26enpJ7Q/QPfu3UlJSWHr1q0Nbvd4PCQkJNRbBDwRLq4eboLgG6t221yNiIhI07E1ALndboYOHcqiRYsC6/x+P4sWLWLkyJENPmfkyJH19gdYsGDBUfcH2L17N/n5+bRv375pCg8jmf3aAbB6ZwGWpbPBRESkdbD9LLCpU6fy7LPP8sILL7Bx40ZuvvlmSktLmTx5MgDXX38999xzT2D/2267jfnz5/PII4+wadMm7r//fr766ituvfVWAEpKSrjrrrtYvnw527dvZ9GiRYwbN46ePXuSlZVly3sMZf3bJ+JyOsgrqWRfYYXd5YiIiDQJ28cAjR8/nv379zNt2jSys7MZMmQI8+fPDwx03rlzJ05nXU4788wzeemll/j973/PvffeS69evXjrrbcYMGAAAC6Xi7Vr1/LCCy9QUFBAhw4duPDCC3nooYfweDy2vMdQFu120Sctng37ili7u4AOSdF2lyQiInLSHJb6NY5QVFREYmIihYWFGg+EuTL8y1/s4ufn9ODui/raXY6IiEiDTuTvt+1dYBL8BnVKAuCdNXtYs6vA1lpERESaggKQ/KAL+qfRLt7D3sIKbvrnV5oTSEREQp4CkPyglDgPC+44h6SYSPYXV/LVjoN2lyQiInJSFIDkuCTGRDK6rxmYPv+bhmfpFhERCRUKQHLcsk4xAej9b/ZRVFFlczUiIiKNpwAkx+1HvVNJS/CQU1TJ//5zJZXVDV9bTUREJNgpAMlxi4p08Y+Jw4l1u1j2fT5TX/0an1+zKIiISOhRAJITMqBjIk//z1AiXQ7mrd3Hba+spqDMa3dZIiIiJ0QBSE7Y2b1SeeKaU4lwOnh37T7OnPkRjy/cQrlXXWIiIhIaFICkUS4a2J45k0+nf/sEyrw+/rLwW0Y/soR3vt6ri6aKiEjQ06UwGqBLYRw/y7J4d+0+Zr6/iT0F5QD0bBfHuMEduGhgOj3bxdtcoYiIhIsT+futANQABaATV1Hl49mPv+eppd9RdkhX2MjubfnpiC6c17cdcR7br70rIiKtmALQSVIAarziiireXbuPBRtyWLI5l9qTxNwuJxecksbDVw4iVkFIRESagQLQSVIAahp7Csp5ecVO3lu3j+/zSgH4zZg+/OLcnjZXJiIirZGuBi9BoWNSNHdm9eGjO8/lD5cPAODF5Ts1d5CIiNhOAUhaxFVDO5EYHcmegnI+3rLf7nJERCTMKQBJi4iKdHHpoPYAfPJtns3ViIhIuFMAkhZzRve2AHyxPd/mSkREJNwpAEmLOb1bMgAb9hbpavIiImIrBSBpMWkJUWS0jcFvwb+X79CM0SIiYhsFIGlRtd1gD8/fzF2vr6XK57e5IhERCUeakU5a1G2Zvais9vPO13t5feVuNuwtYtKoDM7s0ZZObWLsLk9ERMKEJkJsgCZCbH6LNuZw+ytrKK6sDqzrkBhFn/R42sVHkRrvCSztDrkf41ZmFxGRhmkm6JOkANQy8ksqeWHZDj7Zsp+1uwuPa4LEWLeLdglRJEZHEutxEeuOINYTQYzbFbiN80QQ447AE+HEE+nE7XLiiXThdjlxRzjN+oja+y4iXA4inU5cLgcRTgeRLidOBzgcjhb4KYiISFNRADpJCkAtr6SymnW7C9mRX8r+4kr2l1Sa2+JKcosryS2uoKKqZccLRbocuJwOIpwmELmc5rHT4QjcdzkduBwOnIfcRjhrH3PE/rX3za3Z7nCY5x6+3uk4cv/a16n/vPrrzfNqjnFYfeZ5HFF37b5OB3XrD63dccjzDlvvdHJYnXXrj3wfCpYi0nxO5O+3+hMkKMR5IhjZoy0je7RtcLtlWZR6fSYQFVVQVFFNmbeakspqyip9lHqrKfP6ah5XU1Lpo7Lah7faj9fnp7LK3Hqr/YH1ldXmcfVRWp6qfBZVPgvQQO2m5HQ0HIwaComRLgeeCBeeyNqWOxdRkea2toUvcD/CtPQdehvnMS2EsW4XMe4IYj11t9GRLoUxkTCmACQhweFwEOeJIM4TQbeU2CY9tmVZVPstqn0W1X4/1T6Lqprbap+Fz7Lw+S38NbeH3je3BNb7LAv/4fcP2/fwdebxYetrn3/I+sOP67c4yutRd9xD6645lv/w91P7GrX1BLZT7/0G6j+sRp/fwqqp5Xi6Mf0W+H0WYH/jc3Skixi3i6ia2+hD70eax9H1HkcQHek0690RRz4/0nTFJsVEEunSSbYiwUwBSMKeo6alIdIF4LK7nJB3RMCrCVL1gtyhwamhsFgTtKp8pqWustpHZdUh96tNq15Fle+IdbX3y6t8lNa0BpZ5qymtuS3z+gK1llf5KK/yHePdNF58VARtYty0iXWTEBVBuddH17axDO6cSEbbWDokRZMc6yYxOhKXUy1RIi1NY4AaoDFAIq2X32+ZcOStprLKT5nXhKAybzUVVT7z2Ouru19lHpcf8rjCe+S22vul3mpO5LdqYnQk/3NGV7q2jaFnuzj6pMcT6XKqBUmkETQGSETkKJxOhxkX5GmeX38+v0VheRUHy7wUlHk5UFpFYXkVnggnG/cV8W1OCdvzS8kpqqC4oprC8iqeXLz1iOP0ahdHWkIU3VNjyTolnZQ4D73T4jRuSaSJqAWoAWoBEpGWUOXzM2/tPhZuzKGgrIpN2cXklVQedf9ObaI5u1cKCVGRjOiezPCMZOKjIluwYpHgptPgT5ICkIjYpbCsikqfjy+2HaDM62PBhhy+31/CnoLyI6aCcDqgd5rpMuuTHs9ZPVNoE+smzuPC5XQyuFOiWowkrCgAnSQFIBEJNuVeHx9v2c83ewrJK/Hy6db97DpQfsznDO3ahvSEKNITo+jcJpoubWPo3CaGTm1iiHZrwL+0PgpAJ0kBSERCQU5RRc0s6n4Wbcxlb2E5+worKPf6yC/x4j3GxYaTYiJJifOQEucmOdZt5keqOb0/xu2qWermTIr1RBDtNrOvH7o9KtKpViYJGgpAJ0kBSERC3Y78Uj7+dj9en8XegnJ2HShj18Fydh8oq3cNvpPlcEBMzRxJbtfhs6Efa/b0ugkxIw6fBLNmn0OPY2Ynp+aYziNmQK83u3mDM7Ob5zsws5o7HA4cgLOBdQ7HIetqHte820PWOeptq30Oh22ngeNRu29gW83+J/B6NVsDx2jocznaPodvq7+OI/bnsGMcuqk2/Db0vB+qL94TSWJM045h01lgIiJhrmvbWP5n5JGThlqWOUstp6iSvBKzHCz1Ulblo6yy9vT+2nmT6uZOqj3Fv/a2djySZUGp10ept3nmU5LW6xfn9uA3Y/ra9voKQCIiYcThcJAU4yYpxk0f4ht9nEPnUyr3+iit9FHt99fNih6Y4LJ2lnB/YNb0Q2dVP3wiTL/fzMxeb/Z0q25W9qPvZzWwHzX7+QPHsSwLCzMjeW0HiGWBhanVwqp5DNSsr9uHwPMD+9RstA45jmURmAuq9jkctv3QbXWvdci+Rzle3UvW7Vd77MC2Q2o+dJ/6+1lHrKs71iHbDt+ngW00+Do/XF+EzROAKgCJiMgJa+75lESam6YaFRERkbCjACQiIiJhRwFIREREwo4CkIiIiIQdBSAREREJOwpAIiIiEnYUgERERCTsKACJiIhI2FEAEhERkbCjACQiIiJhRwFIREREwo4CkIiIiIQdBSAREREJOwpAIiIiEnYi7C4gGFmWBUBRUZHNlYiIiMjxqv27Xft3/FgUgBpQXFwMQOfOnW2uRERERE5UcXExiYmJx9zHYR1PTAozfr+fvXv3Eh8fj8PhaNJjFxUV0blzZ3bt2kVCQkKTHluajz630KTPLTTpcws9wfKZWZZFcXExHTp0wOk89igftQA1wOl00qlTp2Z9jYSEBP3HDkH63EKTPrfQpM8t9ATDZ/ZDLT+1NAhaREREwo4CkIiIiIQdBaAW5vF4mD59Oh6Px+5S5ATocwtN+txCkz630BOKn5kGQYuIiEjYUQuQiIiIhB0FIBEREQk7CkAiIiISdhSAREREJOwoALWg2bNnk5GRQVRUFCNGjOCLL76wu6Sw9vHHHzN27Fg6dOiAw+HgrbfeqrfdsiymTZtG+/btiY6OJjMzky1bttTb58CBA0yYMIGEhASSkpK44YYbKCkpacF3EV5mzJjB8OHDiY+Pp127dlx++eVs3ry53j4VFRXccssttG3blri4OK688kpycnLq7bNz504uueQSYmJiaNeuHXfddRfV1dUt+VbCylNPPcWgQYMCk+SNHDmS999/P7Bdn1lomDlzJg6Hg9tvvz2wLpQ/OwWgFjJ37lymTp3K9OnTWbVqFYMHDyYrK4vc3Fy7SwtbpaWlDB48mNmzZze4/eGHH+aJJ57g6aefZsWKFcTGxpKVlUVFRUVgnwkTJrB+/XoWLFjAu+++y8cff8yUKVNa6i2EnaVLl3LLLbewfPlyFixYQFVVFRdeeCGlpaWBfe644w7++9//8tprr7F06VL27t3Lj3/848B2n8/HJZdcgtfr5fPPP+eFF15gzpw5TJs2zY63FBY6derEzJkzWblyJV999RXnn38+48aNY/369YA+s1Dw5Zdf8swzzzBo0KB660P6s7OkRZx++unWLbfcEnjs8/msDh06WDNmzLCxKqkFWG+++Wbgsd/vt9LT063/+7//C6wrKCiwPB6P9fLLL1uWZVkbNmywAOvLL78M7PP+++9bDofD2rNnT4vVHs5yc3MtwFq6dKllWeYzioyMtF577bXAPhs3brQAa9myZZZlWdZ7771nOZ1OKzs7O7DPU089ZSUkJFiVlZUt+wbCWJs2bay///3v+sxCQHFxsdWrVy9rwYIF1jnnnGPddtttlmWF/v83tQC1AK/Xy8qVK8nMzAysczqdZGZmsmzZMhsrk6PZtm0b2dnZ9T6zxMRERowYEfjMli1bRlJSEsOGDQvsk5mZidPpZMWKFS1eczgqLCwEIDk5GYCVK1dSVVVV73Pr27cvXbp0qfe5DRw4kLS0tMA+WVlZFBUVBVokpPn4fD5eeeUVSktLGTlypD6zEHDLLbdwySWX1PuMIPT/v+liqC0gLy8Pn89X7x8AQFpaGps2bbKpKjmW7OxsgAY/s9pt2dnZtGvXrt72iIgIkpOTA/tI8/H7/dx+++2MGjWKAQMGAOYzcbvdJCUl1dv38M+toc+1dps0j3Xr1jFy5EgqKiqIi4vjzTffpH///qxZs0afWRB75ZVXWLVqFV9++eUR20L9/5sCkIiEpFtuuYVvvvmGTz/91O5S5Dj06dOHNWvWUFhYyOuvv87EiRNZunSp3WXJMezatYvbbruNBQsWEBUVZXc5TU5dYC0gJSUFl8t1xMj4nJwc0tPTbapKjqX2cznWZ5aenn7EIPbq6moOHDigz7WZ3Xrrrbz77rssXryYTp06Bdanp6fj9XopKCiot//hn1tDn2vtNmkebrebnj17MnToUGbMmMHgwYN5/PHH9ZkFsZUrV5Kbm8tpp51GREQEERERLF26lCeeeIKIiAjS0tJC+rNTAGoBbreboUOHsmjRosA6v9/PokWLGDlypI2VydF069aN9PT0ep9ZUVERK1asCHxmI0eOpKCggJUrVwb2+eijj/D7/YwYMaLFaw4HlmVx66238uabb/LRRx/RrVu3etuHDh1KZGRkvc9t8+bN7Ny5s97ntm7dunrhdcGCBSQkJNC/f/+WeSOC3++nsrJSn1kQGz16NOvWrWPNmjWBZdiwYUyYMCFwP6Q/O1uHYIeRV155xfJ4PNacOXOsDRs2WFOmTLGSkpLqjYyXllVcXGytXr3aWr16tQVYjz76qLV69Wprx44dlmVZ1syZM62kpCTr7bffttauXWuNGzfO6tatm1VeXh44xpgxY6xTTz3VWrFihfXpp59avXr1sq699lq73lKrd/PNN1uJiYnWkiVLrH379gWWsrKywD4///nPrS5dulgfffSR9dVXX1kjR460Ro4cGdheXV1tDRgwwLrwwgutNWvWWPPnz7dSU1Ote+65x463FBbuvvtua+nSpda2bdustWvXWnfffbflcDisDz/80LIsfWah5NCzwCwrtD87BaAW9Ne//tXq0qWL5Xa7rdNPP91avny53SWFtcWLF1vAEcvEiRMtyzKnwt93331WWlqa5fF4rNGjR1ubN2+ud4z8/Hzr2muvteLi4qyEhARr8uTJVnFxsQ3vJjw09HkB1vPPPx/Yp7y83PrFL35htWnTxoqJibGuuOIKa9++ffWOs337duuiiy6yoqOjrZSUFOvXv/61VVVV1cLvJnz87Gc/s7p27Wq53W4rNTXVGj16dCD8WJY+s1ByeAAK5c/OYVmWZU/bk4iIiIg9NAZIREREwo4CkIiIiIQdBSAREREJOwpAIiIiEnYUgERERCTsKACJiIhI2FEAEhERkbCjACQichyWLFmCw+E44rpHIhKaFIBEREQk7CgAiYiISNhRABKRkOD3+5kxYwbdunUjOjqawYMH8/rrrwN13VPz5s1j0KBBREVFccYZZ/DNN9/UO8Ybb7zBKaecgsfjISMjg0ceeaTe9srKSn7729/SuXNnPB4PPXv25B//+Ee9fVauXMmwYcOIiYnhzDPPZPPmzc37xkWkWSgAiUhImDFjBv/85z95+umnWb9+PXfccQfXXXcdS5cuDexz11138cgjj/Dll1+SmprK2LFjqaqqAkxwufrqq7nmmmtYt24d999/P/fddx9z5swJPP/666/n5Zdf5oknnmDjxo0888wzxMXF1avjd7/7HY888ghfffUVERER/OxnP2uR9y8iTUsXQxWRoFdZWUlycjILFy5k5MiRgfU33ngjZWVlTJkyhfPOO49XXnmF8ePHA3DgwAE6derEnDlzuPrqq5kwYQL79+/nww8/DDz/N7/5DfPmzWP9+vV8++239OnThwULFpCZmXlEDUuWLOG8885j4cKFjB49GoD33nuPSy65hPLycqKiopr5pyAiTUktQCIS9LZu3UpZWRkXXHABcXFxgeWf//wn3333XWC/Q8NRcnIyffr0YePGjQBs3LiRUaNG1TvuqFGj2LJlCz6fjzVr1uByuTjnnHOOWcugQYMC99u3bw9Abm7uSb9HEWlZEXYXICLyQ0pKSgCYN28eHTt2rLfN4/HUC0GNFR0dfVz7RUZGBu47HA7AjE8SkdCiFiARCXr9+/fH4/Gwc+dOevbsWW/p3LlzYL/ly5cH7h88eJBvv/2Wfv36AdCvXz8+++yzesf97LPP6N27Ny6Xi4EDB+L3++uNKRKR1kstQCIS9OLj47nzzju544478Pv9nHXWWRQWFvLZZ5+RkJBA165dAXjwwQdp27YtaWlp/O53vyMlJYXLL78cgF//+tcMHz6chx56iPHjx7Ns2TKefPJJ/va3vwGQkZHBxIkT+dnPfsYTTzzB4MGD2bFjB7m5uVx99dV2vXURaSYKQCISEh566CFSU1OZMWMG33//PUlJSZx22mnce++9gS6omTNnctttt7FlyxaGDBnCf//7X9xuNwCnnXYar776KtOmTeOhhx6iffv2PPjgg0yaNCnwGk899RT33nsvv/jFL8jPz6dLly7ce++9drxdEWlmOgtMREJe7RlaBw8eJCkpye5yRCQEaAyQiIiIhB0FIBEREQk76gITERGRsKMWIBEREQk7CkAiIiISdhSAREREJOwoAImIiEjYUQASERGRsKMAJCIiImFHAUhERETCjgKQiIiIhB0FIBEREQk7/x+W73iMYc44rwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667ec535-ac8f-42f9-a1a1-3819a027161e"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "# The purpose of evaluating the model on the test dataset is to assess the model's generalization performance on unseen data.\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1602 - acc: 0.8242\n",
            "\n",
            "acc: 82.42%\n",
            "loss: 0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92918782-8801-4044-b776-3cbbd4c2cc9f"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 62 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 63 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 64 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 65 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 67 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 68 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 71 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 78 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 79 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 80 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 83 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 87 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 88 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 89 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 90 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 91 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 75 Wrong Prediction : 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "13e2b491-5527-4dc1-955c-195cb238e6d0"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "# A Confusion Matrix is a performance measurement tool used in machine learning to evaluate the performance of a classification model.\n",
        "# It also summarizes the performance by tabulating the counts of correct and incorrect predictions made by the model.\n",
        "# TP stands for True Positives. These are the cases where the model correctly predicts the positive class.\n",
        "# FP stands for False Positives. These are the cases where the model incorrectly predicts the positive class.\n",
        "# FN stands for False Negatives. These are the cases where the model incorrectly predicts the negative class.\n",
        "# TN stands for True Negatives. These are the cases where the model correctly predicts the negative class.\n",
        "\n",
        "### 16. Explain the classification report produce.\n",
        "# From the classification report produced, we can see that the model performs well which it have high metrics score\n",
        "# The accuracy for the model is 91 and the f1-score for the model is 0.82\n",
        "# This shows that the classification algorithm works well with the dataset and it can predict unseen data with most accuracy\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.78      0.80        41\n",
            "           1       0.83      0.86      0.84        50\n",
            "\n",
            "    accuracy                           0.82        91\n",
            "   macro avg       0.82      0.82      0.82        91\n",
            "weighted avg       0.82      0.82      0.82        91\n",
            "\n"
          ]
        }
      ]
    }
  ]
}